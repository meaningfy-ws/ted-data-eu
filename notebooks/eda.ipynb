{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This python notebook is used to perform Exploratory Data Analysis (EDA) on fields from TED data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Select the necessary columnson from database on which the EDA will be made."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ted_data_eu.services.etl_pipelines.postgres_etl_pipeline import POSTGRES_URL, SQLALCHEMY_ISOLATION_LEVEL\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DB_QUERY = f\"\"\"\n",
    "            SELECT\n",
    "                contact_point.\"ContactPointId\",\n",
    "                contact_point.\"ContactPointFax\",\n",
    "                contact_point.\"ContactPointTelephone\",\n",
    "                contact_point.\"ContactPointName\",\n",
    "                contact_email.\"Email\",\n",
    "                contact_internet_addr.\"InternetAddress\"\n",
    "            FROM public.\"ContactPoint\" contact_point\n",
    "            JOIN public.\"ContactPointEmail\" contact_email\n",
    "                ON contact_point.\"ContactPointId\" = contact_email.\"ContactPointId\"\n",
    "            JOIN public.\"ContactPointInternetAddress\" contact_internet_addr\n",
    "                ON contact_point.\"ContactPointId\" = contact_internet_addr.\"ContactPointId\"\n",
    "            \"\"\"\n",
    "\n",
    "COLUMNS = {\n",
    "    'ContactPointFax': str,\n",
    "    'ContactPointTelephone': str,\n",
    "    'ContactPointName': str,\n",
    "    'Email': str,\n",
    "    'InternetAddress': str\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-07-24T20:39:15.801290729Z",
     "start_time": "2023-07-24T20:39:15.443874546Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Create a folder and declare the path where the csv file will be created"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def create_csv_file_path():\n",
    "    \"\"\"\n",
    "    Creates a directory named \"data\" (if it doesn't exist already) and returns the path to the CSV file \"eda_data.csv\" within that directory\n",
    "    :return: the path to the CSV file\n",
    "    \"\"\"\n",
    "    data_dir = Path(\"data\")\n",
    "    if not data_dir.exists():\n",
    "        data_dir.mkdir()\n",
    "    return data_dir / \"eda_data.csv\"\n",
    "\n",
    "CSV_FILE_PATH = create_csv_file_path()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T20:39:15.819966359Z",
     "start_time": "2023-07-24T20:39:15.553276579Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Connect with the database and download the data in the csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "sql_engine = sqlalchemy.create_engine(POSTGRES_URL, echo=False, isolation_level=SQLALCHEMY_ISOLATION_LEVEL)\n",
    "with sql_engine.connect() as sql_connection:\n",
    "    df = pd.read_sql(DB_QUERY, sql_connection)\n",
    "df.to_csv (CSV_FILE_PATH, index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-07-24T20:40:10.099703138Z",
     "start_time": "2023-07-24T20:39:15.580947149Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "For each field in the table, represent the distribution by the number of characters (bar chart) and calculate std, average, percentile1, percentile99, min, max, median, iqr, z-score."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import phonenumbers\n",
    "\n",
    "\n",
    "def add_sphere_trace(fig, x, color, label):\n",
    "    \"\"\"\n",
    "    Creates spheres of indicators in the histogram\n",
    "    :param fig: the figure itself\n",
    "    :param x: calculated indicators\n",
    "    :param color: the color of the sphere\n",
    "    :param label: the name of the sphere representing the indicator\n",
    "    :return: the ID of the added view\n",
    "    \"\"\"\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x],\n",
    "        y=[0],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            symbol='circle',\n",
    "            color=color,\n",
    "            line=dict(color='black', width=1),\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        name=label\n",
    "    ))\n",
    "\n",
    "def generate_histogram(data, column, nbinsx):\n",
    "    \"\"\"\n",
    "    Generates the histogram of each field from the table\n",
    "    :param data: the length of each field\n",
    "    :param column: name of the column\n",
    "    :param nbinsx: number of bins\n",
    "    :return: the figure with the histogram result\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    std = data.std()\n",
    "    average = data.mean()\n",
    "    percentile1 = data.quantile(0.01)\n",
    "    percentile99 = data.quantile(0.99)\n",
    "    min = data.min()\n",
    "    max = data.max()\n",
    "    median = data.median()\n",
    "    z_score = (data - average) / std\n",
    "    iqr = data.quantile(0.75) - data.quantile(0.25)\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=data, nbinsx=nbinsx))\n",
    "    std_line_color = 'white'\n",
    "    std_line_width = 6\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=0,\n",
    "        y0=std,\n",
    "        x1=nbinsx,\n",
    "        y1=std,\n",
    "        line=dict(color=std_line_color, width=std_line_width, dash=\"dash\"),\n",
    "        layer='below'\n",
    "    )\n",
    "    add_sphere_trace(fig, average, 'red', 'Average')\n",
    "    add_sphere_trace(fig, std, 'white', 'STD')\n",
    "    add_sphere_trace(fig, percentile1, 'blue', 'Percentile 1')\n",
    "    add_sphere_trace(fig, percentile99, 'blue', 'Percentile 99')\n",
    "    add_sphere_trace(fig, min, 'green', 'Min')\n",
    "    add_sphere_trace(fig, max, 'green', 'Max')\n",
    "    add_sphere_trace(fig, median, 'orange', 'Median')\n",
    "    add_sphere_trace(fig, z_score, 'purple', 'Z-Score')\n",
    "    add_sphere_trace(fig, iqr, 'yellow', 'IQR')\n",
    "\n",
    "    title = f'<b>Distribution of the length of the string for {column}</b><br>'\n",
    "    title += f'Std: {std:.2f}, Average: {average:.2f}, Percentile 1: {percentile1:.2f}, Percentile 99: {percentile99:.2f}<br>'\n",
    "    title += f'Min: {min:.2f}, Max: {max:.2f}, Median: {median:.2f}, IQR: {iqr:.2f}<br>'\n",
    "    title += f'Z_Score: {z_score.values}<br>'\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='The length of the string',\n",
    "        yaxis_title='Number of records',\n",
    "        title_font=dict(size=14)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in COLUMNS and df[column].dtype == 'object':\n",
    "        df['number_of_characters'] = df[column].str.len()\n",
    "        generate_histogram(df['number_of_characters'], column, nbinsx=100)\n",
    "    elif df[column].dtype == 'int64':\n",
    "        generate_histogram(df[column], column, nbinsx=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Calculate KPIs (data completeness, validity, consistency, uniqueness)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def calculate_data_completeness(column):\n",
    "    \"\"\"\n",
    "    Calculates the data completeness for a specific column in the DataFrame\n",
    "    :param column: name of the column for which data completeness is calculated\n",
    "    :return: data completeness percentage as a floating-point number\n",
    "    \"\"\"\n",
    "    number_of_records = len(df[column])\n",
    "    number_of_records_not_null = df[column].notnull().sum()\n",
    "    data_completeness = (number_of_records_not_null / number_of_records) * 100\n",
    "    return data_completeness\n",
    "\n",
    "def calculate_data_consistency(column):\n",
    "    \"\"\"\n",
    "    Calculates the data consistency for a specific column in the DataFrame\n",
    "    :param df: dataFrame containing the data\n",
    "    :param column: name of the column for which data consistency is calculated\n",
    "    :return:  data consistency percentage as a floating-point number\n",
    "    \"\"\"\n",
    "    number_of_records = len(df[column])\n",
    "    df[f'length {column}'] = df[column].str.len()\n",
    "    percentile_1 = df[f'length {column}'].quantile(0.01)\n",
    "    percentile_99 = df[f'length {column}'].quantile(0.99)\n",
    "    df[f'threshold {column}'] = df[f'length {column}'].between(percentile_1, percentile_99)\n",
    "    number_of_items = df[f'threshold {column}'].sum()\n",
    "    data_consistency = (number_of_items / number_of_records) * 100\n",
    "    return data_consistency\n",
    "\n",
    "def calculate_data_uniqueness(column):\n",
    "    \"\"\"\n",
    "    Calculates the data uniqueness for a specific column in the DataFrame\n",
    "    :param df: dataFrame containing the data\n",
    "    :param column: name of the column for which data uniqueness is calculated\n",
    "    :return: data uniqueness percentage as a floating-point number\n",
    "    \"\"\"\n",
    "    number_of_records = len(df[column])\n",
    "    number_of_unique_values = df[column].nunique()\n",
    "    data_uniqueness = (number_of_unique_values / number_of_records) * 100\n",
    "    return data_uniqueness\n",
    "\n",
    "def calculate_data_completness_int(column):\n",
    "    \"\"\"\n",
    "    Calculates the data completeness for a specific column type int in the DataFrame\n",
    "    :param column: name of the column for which data completeness is calculated\n",
    "    :return: data completeness percentage as a floating-point number\n",
    "    \"\"\"\n",
    "    total_values = len(df[column])\n",
    "    num_non_zeros = (df[column] != 0).sum()\n",
    "    percentage_non_zeros = (num_non_zeros / total_values) * 100\n",
    "    return percentage_non_zeros\n",
    "\n",
    "\n",
    "def is_valid_email(email):\n",
    "    \"\"\"\n",
    "    Checks if an email has a correct pattern\n",
    "    :param email: email\n",
    "    :return: a boolean result based on email pattern\n",
    "    \"\"\"\n",
    "    if isinstance(email, (str, bytes)):\n",
    "        pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "        return bool(re.fullmatch(pattern, email))\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_valid_phone_number(phone_number):\n",
    "    \"\"\"\n",
    "    Checks if a phone number has a correct pattern\n",
    "    :param phone_number: phone_number\n",
    "    :return: a boolean result based on phone pattern\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_number = phonenumbers.parse(phone_number, None)\n",
    "        return phonenumbers.is_valid_number(parsed_number)\n",
    "    except phonenumbers.phonenumberutil.NumberParseException:\n",
    "        return False\n",
    "\n",
    "def is_valid_fax_number(fax_number):\n",
    "    \"\"\"\n",
    "    Checks if a fax number has a correct pattern\n",
    "    :param fax_number: fax_number\n",
    "    :return: a boolean result based on fax pattern\n",
    "    \"\"\"\n",
    "    if isinstance(fax_number, (str, bytes)):\n",
    "        pattern = r\"^\\+[\\d\\s/-]+$\"\n",
    "        return bool(re.match(pattern, fax_number))\n",
    "    return None\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in COLUMNS:\n",
    "        if df[column].apply(lambda x: isinstance(x, str) and not pd.isna(x)).any():\n",
    "            data_completeness = calculate_data_completeness(column)\n",
    "            print(f\"The KPI data completeness in the field {column} is {data_completeness:.2f}%.\")\n",
    "            data_consistency = calculate_data_consistency(column)\n",
    "            print(f\"The KPI data consistency in the field {column} is {data_consistency:.2f}%.\")\n",
    "            data_uniqueness = calculate_data_uniqueness(column)\n",
    "            print(f\"The KPI data uniqueness in the field {column} is {data_uniqueness:.2f}%.\")\n",
    "            email_validation = df[column].apply(is_valid_email)\n",
    "            valid_email_percentage = email_validation.mean() * 100\n",
    "            if valid_email_percentage is not None and valid_email_percentage > 10:\n",
    "                print(f\"The KPI data validity in the field {column} is {valid_email_percentage:.2f}%.\")\n",
    "            phone_validation = df[column].apply(is_valid_phone_number)\n",
    "            valid_telephone_percentage = phone_validation.mean() * 100\n",
    "            if valid_telephone_percentage is not None and valid_telephone_percentage > 10:\n",
    "                print(f\"The KPI data validity in the field {column} is {valid_telephone_percentage:.2f}%\")\n",
    "            fax_validation = df[column].apply(lambda x: is_valid_fax_number(str(x))).sum()\n",
    "            total_number = len(df[column])\n",
    "            valid_fax_percentage = (fax_validation / total_number) * 100\n",
    "            if valid_fax_percentage is not None and valid_fax_percentage > 10:\n",
    "                print(f\"The KPI data validity in the field {column} is {valid_fax_percentage:.2f}%\")\n",
    "        else:\n",
    "            data_completeness_int = calculate_data_completness_int(column)\n",
    "            print(f\"The KPI data completeness in the field {column} is {data_completeness_int:.2f}%.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
